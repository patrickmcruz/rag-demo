# Environment Configuration

# Ollama Configuration
OLLAMA_MODEL=llama3
OLLAMA_BASE_URL=http://localhost:11434

# Embedding Model
EMBEDDING_MODEL=all-MiniLM-L6-v2

# GPU Configuration (Optional)
# USE_GPU=false
# GPU_DEVICE=0

# Paths
DATA_DIR=./data
VECTORSTORE_DIR=./vectorstore

# RAG Configuration
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K_DOCUMENTS=3
TEMPERATURE=0.0

# Logging
LOG_LEVEL=INFO

# LangSmith (Optional - for observability)
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
# LANGCHAIN_API_KEY=your_api_key_here
# LANGCHAIN_PROJECT=rag-demo

# Vertex AI (Optional - for production LLM)
# GOOGLE_CLOUD_PROJECT=your-project-id
# GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json
